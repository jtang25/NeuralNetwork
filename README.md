# Custom Neural Network Implementation for Regression and Multi-Classification using NumPy in Python

## Description
This project presents a hands-on approach to deep learning by building a Multi-Layered Perceptron (MLP) from scratch using Python and NumPy. The neural network is specifically designed to handle both regression and multi-classification tasks, providing a comprehensive learning experience for practitioners.

## Demonstration
Please go to the [jupyter notebook](https://github.com/jtang25/NeuralNetwork/blob/master/notebook.ipynb) to view a demonstration of the neural network on the California Housing Data Set (MNIST is a WIP)

## Key Features
- **Ground-Up Implementation**: Crafted a complete neural network without relying on external libraries, offering a deep understanding of the fundamental concepts behind neural networks.

- **Architectural Design**: The MLP incorporates multiple layers with essential components such as activation functions, weight initialization, and bias handling to capture intricate relationships within the data.

- **Optimization Techniques**: Implemented backpropagation coupled with Stochastic Gradient Descent (SGD) to enhance the network's performance and achieve efficient learning.

- **Auto Differentiation**: Leveraged reverse mode auto differentiation for automatic gradient computation during the backward pass, simplifying the training process.

- **Task Versatility**: Successfully demonstrated the network's proficiency in both regression and multi-classification tasks, making it adaptable for various machine learning applications.

- **Benchmark Performance**: The project underwent benchmark tests on popular datasets like MNIST and California Housing, showcasing competitive performance comparable to models developed using established deep learning frameworks.
